{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TITANIC SUBMISSION SET 03\n",
    "Evaluation metric: Accuracy\n",
    "\n",
    "The random forest performed better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA MUNGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_mapping = {\n",
    "    'Mr':['Mr','Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col'],\n",
    "    'Mrs':['Countess', 'Mme','Mrs'],\n",
    "    'Miss':['Mlle', 'Ms','Miss'],\n",
    "    'Master':['Master'],\n",
    "    'Dr':['Dr']\n",
    "}\n",
    "\n",
    "def MatchTitles(title):\n",
    "    for i in title_mapping:\n",
    "        if title in title_mapping[i]:\n",
    "            return i\n",
    "\n",
    "def MatchSubstrings(main_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if main_string.find(substring) != -1:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def Munge(data):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # lower case the column names\n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    # extract titles\n",
    "#     titles = ['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n",
    "#               'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\n",
    "#               'Don', 'Jonkheer']\n",
    "#     df['title'] = df.name.map(lambda x: MatchSubstrings(x, titles))\n",
    "    \n",
    "    # group titles\n",
    "#     df['grouped_title'] = df.title.map(MatchTitles)\n",
    "    \n",
    "    # add family size\n",
    "    df['family_size'] = df.parch + df.sibsp + 1\n",
    "    \n",
    "    # missing values for fares (only 1 from testset)\n",
    "    df.ix[df.fare.isnull(), 'fare'] = 0\n",
    "    \n",
    "    # impute missing ages with the mean based on title\n",
    "#     df['impute_age'] = df.age\n",
    "#     df.ix[(df.age.isnull()) & (df.title=='Mr'), 'impute_age'] = np.average(df[df.title=='Mr'].age.dropna())\n",
    "#     df.ix[(df.age.isnull()) & (df.title=='Mrs'), 'impute_age'] = np.average(df[df.title=='Mrs'].age.dropna())\n",
    "#     df.ix[(df.age.isnull()) & (df.title=='Miss'), 'impute_age'] = np.average(df[df.title=='Miss'].age.dropna())\n",
    "#     df.ix[(df.age.isnull()) & (df.title=='Master'), 'impute_age'] = np.average(df[df.title=='Master'].age.dropna())\n",
    "#     df.ix[(df.age.isnull()) & (df.title=='Dr'), 'impute_age'] = np.average(df[df.title=='Dr'].age.dropna())\n",
    "    \n",
    "    # binning age groups into categories\n",
    "#     bins = [0,10,30,60,200]\n",
    "#     names = ['child','adult','senior','aged']\n",
    "#     df['grouped_age'] = pd.cut(df.impute_age, bins, labels=names)\n",
    "    \n",
    "    # create dummies for sex variable\n",
    "    df = df.join(pd.get_dummies(df.sex, prefix='sex'))\n",
    "    df = df.join(pd.get_dummies(df.pclass, prefix='pclass'))\n",
    "    df = df.join(pd.get_dummies(df.embarked, prefix='embarked'))\n",
    "#     df = df.join(pd.get_dummies(df.grouped_title, prefix='title'))\n",
    "#     df = df.join(pd.get_dummies(df.grouped_age, prefix='age'))\n",
    "    \n",
    "    # mappings\n",
    "#     df.sex = df.sex.map({'female': 0, 'male': 1}).astype(int)\n",
    "    \n",
    "    # lower case the column names again before returning\n",
    "#     df.columns = df.columns.str.lower()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv('../data/train.csv', index_col=0)\n",
    "df_test = pd.read_csv('../data/test.csv', index_col=0)\n",
    "\n",
    "# munge data\n",
    "df_train = Munge(df_train)\n",
    "df_test = Munge(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "train, val = train_test_split(df_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex_female', 'sex_male', 'pclass_1', 'pclass_2', 'pclass_3',\n",
       "       'embarked_C', 'embarked_Q', 'embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features to exclude\n",
    "excluded_features = ['survived','cabin','sex','ticket','name','embarked','pclass','sibsp','parch','title',\n",
    "                     'grouped_title','age','impute_age','grouped_age', 'family_size','fare']\n",
    "\n",
    "features = df_train.ix[:,~df_train.columns.isin(excluded_features)].columns\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = train.ix[:,features]\n",
    "train_y = train.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr train accuracy: 0.7752808988764045\n",
      "rf train accuracy: 0.812199036918138\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_x, train_y)\n",
    "lr_pred_train = lr.predict(train_x)\n",
    "print('lr train accuracy: {result}'.format(result=accuracy_score(train_y, lr_pred_train)))\n",
    "\n",
    "# random forest\n",
    "rf = RandomForestClassifier(criterion='entropy', n_estimators=500, random_state=0, n_jobs=3)\n",
    "rf.fit(train_x, train_y)\n",
    "rf_pred_train = rf.predict(train_x)\n",
    "print('rf train accuracy: {result}'.format(result=accuracy_score(train_y, rf_pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_x = val.ix[:,features]\n",
    "val_y = val.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr validation accuracy: 0.7835820895522388\n",
      "rf validation accuracy: 0.8097014925373134\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "lr_pred_val = lr.predict(val_x)\n",
    "print('lr validation accuracy: {result}'.format(result=accuracy_score(val_y, lr_pred_val)))\n",
    "\n",
    "# random forest\n",
    "rf_pred_val = rf.predict(val_x)\n",
    "print('rf validation accuracy: {result}'.format(result=accuracy_score(val_y, rf_pred_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SubmitCSV(data, filename):\n",
    "    data = pd.Series(submission, index=df_test.index, name='Survived')\n",
    "    pd.DataFrame(data).to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = rf.predict(df_test.ix[:,features])\n",
    "SubmitCSV(submission, '../submissions/submit04_randomforest.csv')\n",
    "\n",
    "submission = lr.predict(df_test.ix[:,features])\n",
    "SubmitCSV(submission, '../submissions/submit05_logisticreg.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.4",
   "language": "python",
   "name": "python34"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
