{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TITANIC SUBMISSION SET 05\n",
    "Evaluation metric: Accuracy\n",
    "\n",
    "Much of this set was taken from Elena Cuco's [blog](http://elenacuoco.altervista.org/blog/archives/1195). It has an excellent example of data munging and cross validation with grid search to fit a random forest. It helped me to move up to the top 25% with an accuracy of 0.79904."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "from patsy import dmatrices\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA MUNGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_mapping = {\n",
    "    'Mr':['Mr','Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col'],\n",
    "    'Mrs':['Countess', 'Mme','Mrs'],\n",
    "    'Miss':['Mlle', 'Ms','Miss'],\n",
    "    'Master':['Master']\n",
    "}\n",
    "\n",
    "def MatchTitles(x):    \n",
    "    for i in title_mapping:\n",
    "        if x.title in title_mapping[i]:\n",
    "            return i\n",
    "        elif x.title == 'Dr':\n",
    "            if x.sex == 'male':\n",
    "                return 'Mr'\n",
    "            else:\n",
    "                return 'Mrs'\n",
    "\n",
    "def MatchSubstrings(main_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if main_string.find(substring) != -1:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def Munge(data):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # lower case the column names\n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    # missing values for fares (only 1 from testset)\n",
    "    df.ix[df.fare.isnull(), 'fare'] = 0\n",
    "    \n",
    "    # add family size\n",
    "    df['family_size'] = df.parch + df.sibsp\n",
    "    df['fare_per_person'] = df.fare / (df.family_size+1)\n",
    "\n",
    "    # extract titles\n",
    "    titles = ['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n",
    "              'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\n",
    "              'Don', 'Jonkheer']\n",
    "    df['title'] = df.name.map(lambda x: MatchSubstrings(x, titles))\n",
    "    \n",
    "    # group titles\n",
    "    df['grouped_title'] = df.apply(MatchTitles, axis=1)\n",
    "    \n",
    "    # impute missing ages with the mean based on title\n",
    "    df['impute_age'] = df.age\n",
    "    df.ix[(df.age.isnull()) & (df.grouped_title=='Mr'), 'impute_age'] = np.average(df[df.grouped_title=='Mr'].age.dropna())\n",
    "    df.ix[(df.age.isnull()) & (df.grouped_title=='Mrs'), 'impute_age'] = np.average(df[df.grouped_title=='Mrs'].age.dropna())\n",
    "    df.ix[(df.age.isnull()) & (df.grouped_title=='Miss'), 'impute_age'] = np.average(df[df.grouped_title=='Miss'].age.dropna())\n",
    "    df.ix[(df.age.isnull()) & (df.grouped_title=='Master'), 'impute_age'] = np.average(df[df.grouped_title=='Master'].age.dropna())\n",
    "    \n",
    "    # binning age groups into categories\n",
    "    bins = [0,10,30,60,200]\n",
    "    names = ['child','adult','senior','aged']\n",
    "    df['grouped_age'] = pd.cut(df.impute_age, bins, labels=names)\n",
    "\n",
    "    # encoding categorical variables\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    le.fit(df.sex)\n",
    "    x_sex = le.transform(df.sex)\n",
    "    df.sex = x_sex.astype(np.float)\n",
    "    \n",
    "    le.fit(df.grouped_title)\n",
    "    x_grouped_title = le.transform(df.grouped_title)\n",
    "    df.grouped_title = x_grouped_title.astype(np.float)\n",
    "    \n",
    "    le.fit(df.grouped_age)\n",
    "    x_age = le.transform(df.grouped_age)\n",
    "    df.grouped_age = x_age.astype(np.float)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv('../data/train.csv', index_col=0)\n",
    "df_test = pd.read_csv('../data/test.csv', index_col=0)\n",
    "\n",
    "# munge data\n",
    "df_train = Munge(df_train)\n",
    "df_test = Munge(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENDER, CLASS, FARE, FAMILY SIZE, FARE PER PERSON, TITLE, AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "formula_ml='survived~pclass+C(grouped_title)+sex+C(grouped_age)+fare_per_person+fare+family_size'\n",
    "train_y, train_x = dmatrices(formula_ml, data=df_train, return_type='dataframe')\n",
    "train_y = np.asarray(train_y).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.860140 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.811189 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.769231 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.853147 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.846154 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.783217 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.825175 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.818182 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.839161 -   0.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................................... , score=0.811189 -   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    6.1s finished\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "rf = RandomForestClassifier(criterion='entropy', n_estimators=500, \n",
    "                            max_depth=5, min_samples_split=1, min_samples_leaf=1,\n",
    "                            max_features='auto', random_state=123, n_jobs=1)\n",
    "\n",
    "# params\n",
    "param_grid = dict( )\n",
    "\n",
    "##classify pipeline\n",
    "pipeline = Pipeline([('rf',rf)])\n",
    "\n",
    "# grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, verbose=3, scoring='accuracy', \n",
    "                           cv = StratifiedShuffleSplit(train_y, n_iter=10, test_size=0.2, \n",
    "                                                       train_size=None, random_state=123)\n",
    "                          ).fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.822\n",
      "on all train set\n",
      "0.830053540404 [ 0.83193277  0.80168776  0.85654008]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print ('on all train set')\n",
    "scores = cross_val_score(grid_search.best_estimator_, train_x, train_y, cv=3, scoring='accuracy')\n",
    "print(scores.mean(),scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on test set\n",
      "0.838323917137 [ 0.83333333  0.78333333  0.89830508]\n"
     ]
    }
   ],
   "source": [
    "print ('on test set')\n",
    "scores = cross_val_score(grid_search.best_estimator_, val_x, val_y, cv=3, scoring='accuracy')\n",
    "print(scores.mean(),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_final = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SubmitCSV(data, filename):\n",
    "    data = pd.Series(submission, index=df_test.index, name='Survived')\n",
    "    pd.DataFrame(data).to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "df_test['survived'] = [0 for x in range(len(df_test))]\n",
    "test_pred, test_x = dmatrices(formula_ml, data=df_test, return_type='dataframe')\n",
    "test_pred = np.asarray(test_pred).ravel()\n",
    "\n",
    "# run the prediction\n",
    "submission = rf_final.predict(test_x).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SubmitCSV(submission, '../submissions/submit07_randomforest.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.4",
   "language": "python",
   "name": "python34"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
