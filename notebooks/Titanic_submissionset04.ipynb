{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TITANIC SUBMISSION SET 04\n",
    "Evaluation metric: Accuracy\n",
    "\n",
    "The random forest performed better. I'm scaling back the model for this submission to only use gender, class, and fare per person.\n",
    "\n",
    "The score was still lower than submission set 03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA MUNGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_mapping = {\n",
    "    'Mr':['Mr','Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col'],\n",
    "    'Mrs':['Countess', 'Mme','Mrs'],\n",
    "    'Miss':['Mlle', 'Ms','Miss'],\n",
    "    'Master':['Master'],\n",
    "    'Dr':['Dr']\n",
    "}\n",
    "\n",
    "def MatchTitles(title):\n",
    "    for i in title_mapping:\n",
    "        if title in title_mapping[i]:\n",
    "            return i\n",
    "\n",
    "def MatchSubstrings(main_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if main_string.find(substring) != -1:\n",
    "            return substring\n",
    "    return np.nan\n",
    "\n",
    "def Munge(data):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # lower case the column names\n",
    "    df.columns = df.columns.str.lower()\n",
    "    \n",
    "    # missing values for fares (only 1 from testset)\n",
    "    df.ix[df.fare.isnull(), 'fare'] = 0\n",
    "    \n",
    "    # add family size\n",
    "    df['family_size'] = df.parch + df.sibsp\n",
    "    df['fare_per_person'] = df.fare / (df.family_size+1)\n",
    "\n",
    "    # extract titles\n",
    "    titles = ['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n",
    "              'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\n",
    "              'Don', 'Jonkheer']\n",
    "    df['title'] = df.name.map(lambda x: MatchSubstrings(x, titles))\n",
    "    \n",
    "    # group titles\n",
    "    df['grouped_title'] = df.title.map(MatchTitles)\n",
    "    \n",
    "    # impute missing ages with the mean based on title\n",
    "    df['impute_age'] = df.age\n",
    "    df.ix[(df.age.isnull()) & (df.grouped_title=='Mr'), 'impute_age'] = np.average(df[df.title=='Mr'].age.dropna())\n",
    "    df.ix[(df.age.isnull()) & (df.grouped_title=='Mrs'), 'impute_age'] = np.average(df[df.title=='Mrs'].age.dropna())\n",
    "    df.ix[(df.age.isnull()) & (df.grouped_title=='Miss'), 'impute_age'] = np.average(df[df.title=='Miss'].age.dropna())\n",
    "    df.ix[(df.age.isnull()) & (df.grouped_title=='Master'), 'impute_age'] = np.average(df[df.title=='Master'].age.dropna())\n",
    "    df.ix[(df.age.isnull()) & (df.grouped_title=='Dr'), 'impute_age'] = np.average(df[df.title=='Dr'].age.dropna())\n",
    "    \n",
    "    # binning age groups into categories\n",
    "    bins = [0,10,30,60,200]\n",
    "    names = ['child','adult','senior','aged']\n",
    "    df['grouped_age'] = pd.cut(df.impute_age, bins, labels=names)\n",
    "\n",
    "    # encoding categorical variables\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    le.fit(df.sex)\n",
    "    x_sex = le.transform(df.sex)\n",
    "    df.sex = x_sex.astype(np.float)\n",
    "    \n",
    "    le.fit(df.title)\n",
    "    x_title = le.transform(df.title)\n",
    "    df.title = x_title.astype(np.float)\n",
    "    \n",
    "    le.fit(df.grouped_age)\n",
    "    x_age = le.transform(df.grouped_age)\n",
    "    df.grouped_age = x_age.astype(np.float)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv('../data/train.csv', index_col=0)\n",
    "df_test = pd.read_csv('../data/test.csv', index_col=0)\n",
    "\n",
    "# munge data\n",
    "df_train = Munge(df_train)\n",
    "df_test = Munge(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENDER, CLASS, FARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "train, val = train_test_split(df_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pclass', 'sex', 'fare', 'fare_per_person'], dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features to exclude\n",
    "excluded_features = ['survived','cabin','ticket','name','embarked','sibsp','parch','title',\n",
    "                     'grouped_title','age','impute_age','grouped_age', 'family_size']\n",
    "\n",
    "features = df_train.ix[:,~df_train.columns.isin(excluded_features)].columns\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x = train.ix[:,features]\n",
    "train_y = train.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr train accuracy: 0.7849117174959872\n",
      "rf train accuracy: 0.8475120385232745\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_x, train_y)\n",
    "lr_pred_train = lr.predict(train_x)\n",
    "print('lr train accuracy: {result}'.format(result=accuracy_score(train_y, lr_pred_train)))\n",
    "\n",
    "# random forest\n",
    "rf = RandomForestClassifier(criterion='entropy', n_estimators=500, \n",
    "                            max_depth=5, min_samples_split=1, min_samples_leaf=1,\n",
    "                            random_state=123, n_jobs=3)\n",
    "rf.fit(train_x, train_y)\n",
    "rf_pred_train = rf.predict(train_x)\n",
    "print('rf train accuracy: {result}'.format(result=accuracy_score(train_y, rf_pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_x = val.ix[:,features]\n",
    "val_y = val.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr validation accuracy: 0.7873134328358209\n",
      "rf validation accuracy: 0.8134328358208955\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "lr_pred_val = lr.predict(val_x)\n",
    "print('lr validation accuracy: {result}'.format(result=accuracy_score(val_y, lr_pred_val)))\n",
    "\n",
    "# random forest\n",
    "rf_pred_val = rf.predict(val_x)\n",
    "print('rf validation accuracy: {result}'.format(result=accuracy_score(val_y, rf_pred_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SubmitCSV(data, filename):\n",
    "    data = pd.Series(submission, index=df_test.index, name='Survived')\n",
    "    pd.DataFrame(data).to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = rf.predict(df_test.ix[:,features])\n",
    "SubmitCSV(submission, '../submissions/submit06_randomforest.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.4",
   "language": "python",
   "name": "python34"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
